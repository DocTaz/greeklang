import org.apache.tools.ant.filters.ReplaceTokens
import org.apache.commons.io.FilenameUtils

buildscript {
  repositories {
    mavenCentral()
    maven {
      url "http://beta.hpcc.uh.edu/nexus/content/groups/public"
    }
  }
  dependencies {
    classpath group: 'org.apache.commons', name: 'commons-io', version: '1.3.2'
    classpath group : 'edu.unc.epidoc', name: 'transcoder', version : '1.2-SNAPSHOT'
  }
}

task setUpBuildDir() {
  description = "Ensure that work area is built."
  File datasetDir = new File(buildDir,dataset)
  File lexDir = new File(datasetDir,"lexica")
  outputs.dir lexDir
}
setUpBuildDir.doLast {
  if (! buildDir.exists()) {
    buildDir.mkdir()
  }
  File orthoDir = new File(buildDir,dataset)
  if (! orthoDir.exists()) {
    orthoDir.mkdir()
    System.err.println "Created dir " + orthoDir
  }
  File lexDir = new File(orthoDir, "lexica")
  if (! lexDir.exists()) {
    lexDir.mkdir()
    System.err.println "Created dir " + lexDir
  }
}


/////////////////////////////////////////////////////////////////////////////////
// Methods generating statements to include in makefile.
// Stem lexica in SFST can be sucked in efficiently from raw .fst lexicon statements,
// whereas inflectional rules are better handled with compiled transducers.
// We therefore generate two kinds of lists for inclusion in makefile statements.
//
// Generates appropriate statement to add to makefile dependencies
// for lexica in uncompiled .fst files.
String lexiconMakeStatement(File dir) {
  StringBuilder stmt = new StringBuilder("")
  def fileList = []
  /*
  dir.eachFileMatch(~/lex.*.fst/) { fstFile ->
    fileList.add ("${buildDir}/${dataset}/${fstFile.getName()}".toString())
  }
  fileList.each { f ->
    stmt.append(f + " ")
  }
  */
  return stmt.toString()
}

// End methods generating statements to include in makefile.
/////////////////////////////////////////////////////////////////////////////////


/////////////////////////////////////////////////////////////////////////////////
// Methods generating statement to include in FST files.
//
// Generates appropriate SFST-PL statements for including lexica
// in .fst files.
String lexiconFstStatement(File dir) {
  StringBuilder stmt = new StringBuilder("")
  def fileList = []
  if (! dir.exists()) {
    System.err.println "Can't make FST statements for nonexistent dir " + dir
    return ""
  } else {
    dir.eachFileMatch(~/lex.*.fst/) { fstFile ->
      fileList.add ('"' + "${buildDir}/${dataset}/lexica/${fstFile.getName()}".toString() + '"')
    }
    fileList.eachWithIndex { f, i ->
      if (i < (fileList.size() - 1)) {
	stmt.append( f + ' | ')
      } else {
	stmt.append( f )
      }
    }
    return stmt.toString()
  }
}

// Generates  SFST-PL statement to add taxonomic tags
// to FST alphabet of symbols.
String tagsFstStatement() {
  //return "#extratag# = <epic><hmt><ml>"
  return ""
}

// End methods generating statement to include in FST files.
/////////////////////////////////////////////////////////////////////////////////




/////////////////////////////////////////////////////////////////////////////////
// Methods for writing FST statements from simple tabular source.
//

task buildVerbStems(dependsOn: setUpBuildDir) {
}

String nounFstStringForCols(ArrayList columns) {
  StringBuilder nounEntry  = new StringBuilder()
  nounEntry.append("<u>${columns[0]}</u>")
  nounEntry.append("<u>${columns[1]}</u>")
  String stem = columns[2].replaceAll("_", "<lo>")
  stem = stem.replaceAll("\\(", "<ro>")
  stem = stem.replaceAll("\\)", "<sm>")
  nounEntry.append(stem)
  nounEntry.append("<noun>")
  nounEntry.append("<${columns[3]}>")
  nounEntry.append("<${columns[4]}>")
  nounEntry.append("<${columns[5]}>")
  nounEntry.append("\n")
  return nounEntry.toString()
}
task buildNounStems(dependsOn: setUpBuildDir) {
  description = "Builds .fst files from tabular source in ${loaddir}/${dataset}/stems-csv/nouns"

  File lexDir = new File("${loaddir}/${dataset}/stems-csv/nouns")

  File orthoBuild = new File(buildDir,dataset)
  File fstDir = new File(orthoBuild,"lexica")

  outputs.dir fstDir
  inputs.dir lexDir
}

buildNounStems.doLast {
  File lexDir = new File("${loaddir}/${dataset}/stems-csv/nouns")
  File orthoBuild = new File(buildDir,dataset)
  File fstDir = new File(orthoBuild,"lexica")
  if (! fstDir.exists()) {
    fstDir.mkdir()
  }

  System.err.println "Looking for csv files in " + lexDir
  def fileCount = 0
  lexDir.eachFileMatch(~/.*.csv/) { csvFile ->
    File fstFile = new File(fstDir, "lex-nouns-${csvFile.getName().replaceFirst(/.csv/,'.fst')}")
    fstFile.setText("")
    StringBuilder data = new StringBuilder()
    def lineCount = 0
    csvFile.eachLine { l ->
      ArrayList cols = l.split(/,/)

      // CHECK THAT LINE IS NOT EMPTYR
      if ((lineCount > 0) && (cols.size() > 1)) {
        data.append(nounFstStringForCols(cols))
      }
      lineCount++
    }
    System.err.println "${fileCount}. File ${csvFile}"
    if (fileCount > 0) {
     fstFile.append(" \\\\|\n")
    }
    fstFile.append(data.toString())
    fileCount++
  }

}


//task buildStems(dependsOn: [buildNounStems, buildVerbStems, buildAdjectiveStems, buildOtherStems, buildIndeclinableStems]) {
task buildStems(dependsOn: [buildNounStems, buildVerbStems]) {
  description = "Builds .fst files from tabular source in data/stems-csv"
  File orthoBuild = new File(buildDir,dataset)
  File fstDir = new File(orthoBuild,"lexica")
  outputs.dir fstDir
}



task buildAdjectiveInflection() {
  description = "Builds adjectiveinfl.fst from tabular source"

}
task buildAdverbInflection() {
  description = "Builds adverbinl.fst from tabular source"
}
task buildIndeclInflection() {
  description = "Builds indeclinfl.fst from tabular source"
}
task buildInfInflection() {
  description = "Builds infinfl.fst from tabular source"
}
task buildPtcplInflection() {
  description = "Builds ptcplinfl.fst from tabular source"
}
task buildVadjInflection() {
  description = "Builds vadjinfl.fst from tabular source"
}
task buildVerbInflection() {
  description = "Builds verbinfl.fst from tabular source"
}



String nounInflFstForCols(ArrayList cols) {

  if (cols.size() < 6) {
    return ""
  }
  StringBuilder fst = new StringBuilder("")
  String ruleUrn = cols[0].replaceAll(/_/,"\\\\_")
  ruleUrn = ruleUrn.replaceAll("\\.","\\\\.")
  String inflClass = cols[1].replaceAll(/_/,"\\_")
  String inflString = cols[2]
  String grammGender = cols[3]
  String grammCase = cols[4]
  String grammNumber = cols[5]

  inflString = inflString.replaceAll("_", "<lo>")
  inflString = inflString.replaceAll("\\(", "<ro>")
  inflString = inflString.replaceAll("\\)", "<sm>")
  inflString = inflString.replaceAll("\\|", "\\\\|")


  fst.append(" <${inflClass}> <u>${ruleUrn}</u>${inflString}<${grammGender}><${grammCase}><${grammNumber}>")
  return fst.toString()
}
task buildNounInflection(dependsOn: setUpBuildDir) {
  description = "Builds nouninfl.fst from tabular source"
}
buildNounInflection.doLast {
  if (! buildDir.exists()) {
    buildDir.mkdir()
  }
  File orthoBuild = new File(buildDir, dataset)
  if (! orthoBuild.exists()) {
    orthoBuild.mkdir()
  }
  File inflDir = new File(orthoBuild,"inflection")
  if (! inflDir.exists()) {
    inflDir.mkdir()
  }
  File nounFst = new File(inflDir,"nouninfl.fst")
  nounFst.setText("")
  StringBuilder data = new StringBuilder("\$nouninfl\$ = ")

  File lexDir = new File("${loaddir}/${dataset}/rules-csv/nouns")
  def fileCount = 0
  lexDir.eachFileMatch(~/.*.csv/) { csvFile ->
    if (fileCount > 0) {
      data.append(" |\\\n")
    }

    def lineCount = 0
    csvFile.eachLine { l ->
      ArrayList cols = l.split(/,/)
      if (lineCount == 0) {
	// skip
      } else {
	String fstRow = nounInflFstForCols(cols)
	if (fstRow.size() > 1) {
	  if (lineCount == 1) {
	    data.append(fstRow)
	  } else if (lineCount > 1) {
	    data.append(" |\\\n" + fstRow)
	  }
	}
      }
      lineCount++
      }
    fileCount++
  }
  data.append("\n\n\$nouninfl\$\n")
  nounFst.append(data.toString())
}


task buildInflection(dependsOn: [buildNounInflection, buildAdjectiveInflection, buildAdverbInflection,buildIndeclInflection, buildInfInflection, buildPtcplInflection, buildVadjInflection,  buildVadjInflection ]) {
  description = "Builds .fst files from tabular source in data/rules-csv"
}


// End methods for writing FST statements from simple tabular source.
/////////////////////////////////////////////////////////////////////////////////






/////////////////////////////////////////////////////////////////////////////////
// Tasks for copying FST source and definition of orthographic system

task cpSrc (type: Copy, dependsOn: [buildStems]) {
    description = "Filters and copies FST src directory to build area."
    from ("src/fst") {
      include ("**/makefile", "**/*.fst")
    }
    into "${buildDir}/${dataset}"
    filter(
      ReplaceTokens, tokens: [
      "workdir" : buildDir.toString() + "/${dataset}/",
      "lexica": lexiconFstStatement(new File("${buildDir}/${dataset}/lexica")),
      "makelexica": lexiconMakeStatement(new File("${buildDir}/${dataset}/lexica")),

      "extramakerules": "", // rulesMakeStatement(new File("${loaddir}/${dataset}/rules-fst")),
      "extratags": "" //tagsFstStatement()
     ])
    inputs.dir file("${buildDir}/${dataset}/lexica")
}


task cpOrthography(type:Copy, dependsOn: setUpBuildDir) {
    description = "Filters and copies directory with defintions of orthographic system to build area."
    from ("${loaddir}/${dataset}/orthography") {
      include ("**/*.fst")
    }
    into "${buildDir}/${dataset}"
    //filter(ReplaceTokens, tokens: ["workdir" : "${buildDir}/${dataset}/".toString()])
}
cpOrthography.doLast {
  System.err.println "Copied orthography data from ${loaddir}/${dataset}/orthography to ${buildDir}/${dataset}"
}

// End tasks for copying FST source and definition of orthographic system
/////////////////////////////////////////////////////////////////////////////////


task filterCopy (dependsOn: [cpSrc, cpOrthography]) {
}

task cpAll (dependsOn: [filterCopy, buildInflection] ){
  description = "Copies all source material to build area"
}
cpAll.doLast {
  // check that at least one stem lexicon was copied....
}




/////////////////////////////////////////////////////////////////////////////////
// Tasks compiling FSTs

task compileInflection(type:Exec, dependsOn: cpAll) {
  description = "Builds binary Finite State Transducer for core inflection in ${buildDir}/${dataset}/inflection.a"

  outputs.file "${buildDir}/${dataset}/inflection.a".toString()
  inputs.dir "${buildDir}/${dataset}/inflection"

  commandLine =  [MAKE, "-f", "${buildDir}/${dataset}/inflection/makefile".toString()]
}

task fst(type:Exec, dependsOn: [cpAll, compileInflection]) {
  description = "Builds binary Finite State Transducer in ${buildDir}/${dataset}/greek.a"

  outputs.file "${buildDir}/${dataset}/greek.a".toString()
  inputs.dir "${buildDir}/${dataset}"

  commandLine =  [MAKE, "-f", "${buildDir}/${dataset}/makefile".toString()]
}

task fstgen(type:Exec, dependsOn: cpAll) {
  description = "Builds binary Finite State Transducer in ${buildDir}/${dataset}/greek.a and 'switched' FST (for bulk generation of surface symbols) in ${buildDir}/${dataset}/bulkgen.a"

  outputs.file "${buildDir}/${dataset}/bulkgen.a".toString()
  inputs.dir "${buildDir}/${dataset}"

  commandLine =  [FSTCOMPILER, "-s", "${buildDir}/${dataset}/morphology.fst".toString(), "${buildDir}/${dataset}/bulkgen.a".toString()]
}

// End tasks compiling FSTs
/////////////////////////////////////////////////////////////////////////////////



////////////////////////////////////////////////////////////////////////////////////
// Utility transducers, used in testing, helpful in debugging
task rawlex(type:Exec, dependsOn: fst) {
  description = "Builds binary Finite State Transducer in ${buildDir}/${dataset}/rawlex.a"

  outputs.file "${buildDir}/${dataset}/utils/rawlex.a".toString()
  inputs.file "${buildDir}/${dataset}/fst.a"

  commandLine =  [FSTCOMPILER, "${buildDir}/${dataset}/utils/rawlex.fst".toString(), "${buildDir}/${dataset}/utils/rawlex.a".toString()]
}

task rawmorph(type:Exec, dependsOn: fst) {
  description = "Builds binary Finite State Transducer in ${buildDir}/${dataset}/rawmorph.a"

  outputs.file "${buildDir}/${dataset}/utils/rawmorph.a".toString()
  inputs.file "${buildDir}/${dataset}/fst.a"

  commandLine =  [FSTCOMPILER, "${buildDir}/${dataset}/utils/rawmorph.fst".toString(), "${buildDir}/${dataset}/utils/rawmorph.a".toString()]
}

task rawaccepted(type:Exec, dependsOn: rawmorph) {
  description = "Builds binary Finite State Transducer in ${buildDir}/${dataset}/rawaccepted.a"

  outputs.file "${buildDir}/${dataset}/utils/rawaccepted.a".toString()
  inputs.file "${buildDir}/${dataset}/fst.a"

  commandLine =  [FSTCOMPILER, "${buildDir}/${dataset}/utils/rawaccepted.fst".toString(), "${buildDir}/${dataset}/utils/rawaccepted.a".toString()]
}

task utils(dependsOn: [rawlex, rawmorph, rawaccepted]) {
  description = "Compiles utility transducers useful for debugging"
}
utils.doLast {
  System.err.println "Three utility transducers compiled."
}

test.dependsOn utils

test {
  systemProperty 'testForms', testformfile
}


// End utility transducers used in testing
////////////////////////////////////////////////////////////////////////////////////

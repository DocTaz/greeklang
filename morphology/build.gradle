/* ////////////////////////////////////////////////////////////////////////////////

Build file for Kanones.

Main sections:

// Tasks setting up directory tree for working area
// Task to generate appropriate SFST-PL statements for including lexica
// Tasks for writing FST statements for stem lexica from simple tabular source.
// Tasks to build inflectional rules in FST from source data in .csv files
// Tasks for copying FST source and definition of orthographic system
// Tasks for compiling FSTs
// Tasks for building utility transducers, used in testing, helpful in debugging


///////////////////////////////////////////////////////////////////////////////// */


import org.apache.tools.ant.filters.ReplaceTokens
import org.apache.commons.io.FilenameUtils

buildscript {
  repositories {
    mavenCentral()
    maven {
      url "http://beta.hpcc.uh.edu/nexus/content/groups/public"
    }
  }
  dependencies {
    classpath group: 'org.apache.commons', name: 'commons-io', version: '1.3.2'
    classpath group : 'edu.unc.epidoc', name: 'transcoder', version : '1.2-SNAPSHOT'
  }
}



/////////////////////////////////////////////////////////////////////////////////
// Tasks setting up directory tree for working area
//
task setUpInflDir() {
  description = "Ensure that work area is built for inflectional rules."
  File datasetDir = new File(buildDir,dataset)
  File inflDir = new File(datasetDir,"inflection")
  outputs.dir inflDir
}
setUpInflDir.doLast {
  if (! buildDir.exists()) {
    buildDir.mkdir()
  }
  File orthoDir = new File(buildDir,dataset)
  if (! orthoDir.exists()) {
    orthoDir.mkdir()
    System.err.println "Created dir " + orthoDir
  }
  File inflDir = new File(orthoDir, "inflection")
  if (! inflDir.exists()) {
    inflDir.mkdir()
    System.err.println "Created dir " + inflDir
  }
}


task setUpLexDir() {
  description = "Ensure that work area is built for lexica of stems."
  File datasetDir = new File(buildDir,dataset)
  File lexDir = new File(datasetDir,"lexica")
  outputs.dir lexDir
}
setUpLexDir.doLast {
  if (! buildDir.exists()) {
    buildDir.mkdir()
  }
  File orthoDir = new File(buildDir,dataset)
  if (! orthoDir.exists()) {
    orthoDir.mkdir()
    System.err.println "Created dir " + orthoDir
  }
  File lexDir = new File(orthoDir, "lexica")
  if (! lexDir.exists()) {
    lexDir.mkdir()
    System.err.println "Created dir " + lexDir
  }
}
// End tasks setting up directory tree for working area
/////////////////////////////////////////////////////////////////////////////////


/////////////////////////////////////////////////////////////////////////////////
// Generates appropriate SFST-PL statements for including lexica
// in .fst files.
String lexiconFstStatement(File dir) {
  StringBuilder stmt = new StringBuilder("")
  def fileList = []
  if (! dir.exists()) {
    return ""
  } else {
    dir.eachFileMatch(~/lex.*.fst/) { fstFile ->
      fileList.add ('"' + "${buildDir}/${dataset}/lexica/${fstFile.getName()}".toString() + '"')
    }
    fileList.eachWithIndex { f, i ->
      if (i < (fileList.size() - 1)) {
	stmt.append( f + ' | ')
      } else {
	stmt.append( f )
      }
    }
    return stmt.toString()
  }
}
//
/////////////////////////////////////////////////////////////////////////////////




/////////////////////////////////////////////////////////////////////////////////
// Tasks for writing FST statements for stem lexica from simple tabular source.
//


// Irregulars are a little different.
//Source: StemUrn,LexicalEntity,String,Gender,Case,Number
// Target: <u>smyth\.n23069\_0</u><u>lexent\.n23069</u>gunaiko/s<fem><gen><sg><irregnoun>
String irregNounFstStringForCols(ArrayList columns) {
  StringBuilder nounEntry  = new StringBuilder()
  nounEntry.append("<u>${columns[0]}</u>")
  nounEntry.append("<u>${columns[1]}</u>")
  String stem = columns[2].replaceAll("_", "<lo>")
  stem = stem.replaceAll("\\^", "<sh>")
  stem = stem.replaceAll("\\(", "<ro>")
  stem = stem.replaceAll("\\)", "<sm>")
  nounEntry.append(stem)
  nounEntry.append("<${columns[3]}>")
  nounEntry.append("<${columns[4]}>")
  nounEntry.append("<${columns[5]}>")
  nounEntry.append("<irregnoun>")
  nounEntry.append("\n")
  return nounEntry.toString()
}
/*
task buildNounStems(dependsOn: setUpLexDir) {
  description = "Builds .fst files from tabular source in ${loaddir}/${dataset}/stems-csv/nouns"

  File lexDir = new File("${loaddir}/${dataset}/stems-csv/nouns")

  File orthoBuild = new File(buildDir,dataset)
  File fstDir = new File(orthoBuild,"lexica")

  outputs.dir fstDir
  inputs.dir lexDir
}
*/
// StemUrn,LexicalEntity,String,Gender,Case,Number
task buildIrregNouns(dependsOn:setUpLexDir) {
  description = "Builds FST lexicon for irregular nouns from .csv files"

  File lexDir = new File("${loaddir}/${dataset}/irregular-stems-csv/nouns")
  File orthoBuild = new File(buildDir,dataset)
  File fstDir = new File(orthoBuild,"lexica")

  outputs.dir fstDir
  inputs.dir lexDir
}
buildIrregNouns.doLast {
  File lexDir = new File("${loaddir}/${dataset}/irregular-stems-csv/nouns")
  File orthoBuild = new File(buildDir,dataset)
  File fstDir = new File(orthoBuild,"lexica")
  if (! fstDir.exists()) {
    fstDir.mkdir()
  }

  def fileCount = 0
  lexDir.eachFileMatch(~/.*.csv/) { csvFile ->
    File fstFile = new File(fstDir, "lex-irreg-noun-${csvFile.getName().replaceFirst(/.csv/,'.fst')}")
    fstFile.setText("")
    StringBuilder data = new StringBuilder()
    def lineCount = 0
    csvFile.eachLine { l ->
      ArrayList cols = l.split(/,/)

      // CHECK THAT LINE IS NOT EMPTYR
      if ((lineCount > 0) && (cols.size() > 1)) {
        data.append(irregNounFstStringForCols(cols))
      }
      lineCount++
    }
    System.err.println "${fileCount}. File ${csvFile}"
    fstFile.append(data.toString())
    fileCount++
  }

}
task buildIrregAdjectives(dependsOn:setUpLexDir) {
  description = "Builds FST lexicon for irregular adjectives from .csv files"
}
task buildIrregAdverbs(dependsOn:setUpLexDir) {
  description = "Builds FST lexicon for irregular adverbs from .csv files"
}
task buildIrregVerbs(dependsOn:setUpLexDir) {
  description = "Builds FST lexicon for irregular conjugated verb forms from .csv files"
}
task buildIrregInfinitives(dependsOn:setUpLexDir) {
  description = "Builds FST lexicon for irregular infinitives from .csv files"
}
task buildIrregPtcpls(dependsOn:setUpLexDir) {
  description = "Builds FST lexicon for irregular participles from .csv files"
}
task buildIrregVadjs(dependsOn:setUpLexDir) {
  description = "Builds FST lexicon for irregular verbal adjectives from .csv files"
}


task buildIrregStems(dependsOn: [buildIrregNouns, buildIrregAdjectives,buildIrregAdverbs,buildIrregVerbs,buildIrregInfinitives,buildIrregPtcpls,buildIrregPtcpls,buildIrregVadjs ]) {
  description = "Builds FST lexicon for irregular forms from .csv files"
}
buildIrregStems.doLast {
  System.err.println "FST statements for all irregular forms constructed."
}


// SOURCE:  lsjpool.n64316_0,lexent.n64316,lu_,w_regular,
// TARGET: <u>lsjpool.n64316_0</u><u>lexent.n64316</u>lu<lo><verb><w_regular>
String verbFstStringForCols(ArrayList columns) {
  StringBuilder verbEntry  = new StringBuilder()

  verbEntry.append("<u>${columns[0]}</u>")
  verbEntry.append("<u>${columns[1]}</u>")

  String stem = columns[2].replaceAll("_", "<lo>")
  stem = stem.replaceAll("\\^", "<sh>")
  stem = stem.replaceAll("\\(", "<ro>")
  stem = stem.replaceAll("\\)", "<sm>")
  verbEntry.append(stem)
  verbEntry.append("<verb>")
  verbEntry.append("<${columns[3]}>")
  verbEntry.append("\n")
  return verbEntry.toString()
}

task buildVerbStems(dependsOn: setUpLexDir) {
  description = "Builds FST lexicon for verbs from .csv files"
}
buildVerbStems.doLast {
  File lexDir = new File("${loaddir}/${dataset}/stems-csv/verbs-simplex")
  File orthoBuild = new File(buildDir,dataset)
  File fstDir = new File(orthoBuild,"lexica")
  if (! fstDir.exists()) {
    fstDir.mkdir()
  }

  def fileCount = 0
  lexDir.eachFileMatch(~/.*.csv/) { csvFile ->
    File fstFile = new File(fstDir, "lex-verbs-${csvFile.getName().replaceFirst(/.csv/,'.fst')}")
    fstFile.setText("")
    StringBuilder data = new StringBuilder()
    def lineCount = 0
    csvFile.eachLine { l ->
      ArrayList cols = l.split(/,/)

      // CHECK THAT LINE IS NOT EMPTYR
      if ((lineCount > 0) && (cols.size() > 1)) {
        data.append(verbFstStringForCols(cols))
      }
      lineCount++
    }
    System.err.println "${fileCount}. File ${csvFile}"
    if (fileCount > 0) {
     fstFile.append(" \\\\|\n")
    }
    fstFile.append(data.toString())
    fileCount++
  }

}



// SOURCE:
// TARGET:
String nounFstStringForCols(ArrayList columns) {
  StringBuilder nounEntry  = new StringBuilder()
  nounEntry.append("<u>${columns[0]}</u>")
  nounEntry.append("<u>${columns[1]}</u>")
  String stem = columns[2].replaceAll("_", "<lo>")
  stem = stem.replaceAll("\\^", "<sh>")
  stem = stem.replaceAll("\\(", "<ro>")
  stem = stem.replaceAll("\\)", "<sm>")
  nounEntry.append(stem)
  nounEntry.append("<noun>")
  nounEntry.append("<${columns[3]}>")
  nounEntry.append("<${columns[4]}>")
  nounEntry.append("<${columns[5]}>")
  nounEntry.append("\n")
  return nounEntry.toString()
}
task buildNounStems(dependsOn: setUpLexDir) {
  description = "Builds .fst files from tabular source in ${loaddir}/${dataset}/stems-csv/nouns"

  File lexDir = new File("${loaddir}/${dataset}/stems-csv/nouns")

  File orthoBuild = new File(buildDir,dataset)
  File fstDir = new File(orthoBuild,"lexica")

  outputs.dir fstDir
  inputs.dir lexDir
}

buildNounStems.doLast {
  File lexDir = new File("${loaddir}/${dataset}/stems-csv/nouns")
  File orthoBuild = new File(buildDir,dataset)
  File fstDir = new File(orthoBuild,"lexica")

  if (! fstDir.exists()) {
    fstDir.mkdir()
  }

  System.err.println "Looking for csv files in " + lexDir
  def fileCount = 0
  lexDir.eachFileMatch(~/.*.csv/) { csvFile ->
    File fstFile = new File(fstDir, "lex-nouns-${csvFile.getName().replaceFirst(/.csv/,'.fst')}")
    fstFile.setText("")
    StringBuilder data = new StringBuilder()
    def lineCount = 0
    csvFile.eachLine { l ->
      ArrayList cols = l.split(/,/)

      // CHECK THAT LINE IS NOT EMPTYR
      if ((lineCount > 0) && (cols.size() > 1)) {
        data.append(nounFstStringForCols(cols))
      }
      lineCount++
    }
    System.err.println "${fileCount}. File ${csvFile}"
    if (fileCount > 0) {
     fstFile.append(" \\\\|\n")
    }
    fstFile.append(data.toString())
    fileCount++
  }

}









// pronouns
//SOURCE: smyth.lexent.n71882_00,lexent.n71882,t,os_h_on,inflacc
//TARGET: <u>smyth.n71882_00</u><u>lexent.n71882</u>t<pron><os_h_on><inflacc>
String pronFstStringForCols(ArrayList columns) {
  if (columns.size() < 5) {
    return ""
  }
  
  StringBuilder pronEntry  = new StringBuilder()
  pronEntry.append("<u>${columns[0]}</u>")
  pronEntry.append("<u>${columns[1]}</u>")
  String stem = columns[2].replaceAll("_", "<lo>")
  stem = stem.replaceAll("\\^", "<sh>")
  stem = stem.replaceAll("\\(", "<ro>")
  stem = stem.replaceAll("\\)", "<sm>")
  pronEntry.append(stem)
  pronEntry.append("<pron>")
  pronEntry.append("<${columns[3]}>")
  pronEntry.append("<${columns[4]}>")
  pronEntry.append("\n")
  return pronEntry.toString()
}

task buildPronounStems(dependsOn: setUpLexDir) {
  description = "Builds .fst files from tabular source in ${loaddir}/${dataset}/stems-csv/pronouns"

  File lexDir = new File("${loaddir}/${dataset}/stems-csv/pronouns")

  File orthoBuild = new File(buildDir,dataset)
  File fstDir = new File(orthoBuild,"lexica")

  outputs.dir fstDir
  inputs.dir lexDir
}
buildAdjectiveStems.doLast {
  File lexDir = new File("${loaddir}/${dataset}/stems-csv/pronouns")
  File orthoBuild = new File(buildDir,dataset)
  File fstDir = new File(orthoBuild,"lexica")

  System.err.println "Looking for csv files in " + lexDir
  def fileCount = 0
  lexDir.eachFileMatch(~/.*.csv/) { csvFile ->
    File fstFile = new File(fstDir, "lex-prons-${csvFile.getName().replaceFirst(/.csv/,'.fst')}")
    fstFile.setText("")
    StringBuilder data = new StringBuilder()
    def lineCount = 0
    csvFile.eachLine { l ->
      ArrayList cols = l.split(/,/)

      // CHECK THAT LINE IS NOT EMPTYR
      if ((lineCount > 0) && (cols.size() > 1)) {
        data.append(pronFstStringForCols(cols))
      }
      lineCount++
    }
    System.err.println "${fileCount}. File ${csvFile}"
    //if (fileCount > 0) {
      //fstFile.append(" \\\\|\n")
    //}
    fstFile.append(data.toString())
    fileCount++
  }


}

// SOURCE: smythpool.n260_0,lexent.n260,a)gaq,os_h_on,inflacc
// TARGET: <u>smythpool.n260_0</u><u>lexent.n260</u>a<sm>gaq<adj><os_h_on><inflacc>
String adjFstStringForCols(ArrayList columns) {
  if (columns.size() < 5) {
    return ""
  }
  
  StringBuilder adjEntry  = new StringBuilder()
  adjEntry.append("<u>${columns[0]}</u>")
  adjEntry.append("<u>${columns[1]}</u>")
  String stem = columns[2].replaceAll("_", "<lo>")
  stem = stem.replaceAll("\\^", "<sh>")
  stem = stem.replaceAll("\\(", "<ro>")
  stem = stem.replaceAll("\\)", "<sm>")
  adjEntry.append(stem)
  adjEntry.append("<adj>")
  adjEntry.append("<${columns[3]}>")
  adjEntry.append("<${columns[4]}>")
  adjEntry.append("\n")
  return adjEntry.toString()
}
task buildAdjectiveStems(dependsOn: setUpLexDir) {
  description = "Builds .fst files from tabular source in ${loaddir}/${dataset}/stems-csv/adjectives"

  File lexDir = new File("${loaddir}/${dataset}/stems-csv/adjectives")

  File orthoBuild = new File(buildDir,dataset)
  File fstDir = new File(orthoBuild,"lexica")

  outputs.dir fstDir
  inputs.dir lexDir
}
buildAdjectiveStems.doLast {
  File lexDir = new File("${loaddir}/${dataset}/stems-csv/adjectives")
  File orthoBuild = new File(buildDir,dataset)
  File fstDir = new File(orthoBuild,"lexica")

  System.err.println "Looking for csv files in " + lexDir
  def fileCount = 0
  lexDir.eachFileMatch(~/.*.csv/) { csvFile ->
    File fstFile = new File(fstDir, "lex-adjs-${csvFile.getName().replaceFirst(/.csv/,'.fst')}")
    fstFile.setText("")
    StringBuilder data = new StringBuilder()
    def lineCount = 0
    csvFile.eachLine { l ->
      ArrayList cols = l.split(/,/)

      // CHECK THAT LINE IS NOT EMPTYR
      if ((lineCount > 0) && (cols.size() > 1)) {
        data.append(adjFstStringForCols(cols))
      }
      lineCount++
    }
    System.err.println "${fileCount}. File ${csvFile}"
    if (fileCount > 0) {
     fstFile.append(" \\\\|\n")
    }
    fstFile.append(data.toString())
    fileCount++
  }


}

// SOURCE: smythpool.n51951_0,lexent.n51951,kai/,conjunct
// TARGET: <u>smythpool.n51951_0</u><u>lexent.n51951</u>kai/<conjunct>
String indeclFstStringForCols(ArrayList columns) {
  if (columns.size() < 4) {
    return ""
  }
  StringBuilder indeclEntry  = new StringBuilder()
  indeclEntry.append("<u>${columns[0]}</u>")
  indeclEntry.append("<u>${columns[1]}</u>")
  String stem = columns[2].replaceAll("_", "<lo>")
  stem = stem.replaceAll("\\^", "<sh>")
  stem = stem.replaceAll("\\(", "<ro>")
  stem = stem.replaceAll("\\)", "<sm>")
  indeclEntry.append(stem)
  indeclEntry.append("<${columns[3]}>")
  indeclEntry.append("\n")
  return indeclEntry.toString()
}
task buildIndeclinableStems(dependsOn: setUpLexDir) {
}
buildIndeclinableStems.doLast {
  File lexDir = new File("${loaddir}/${dataset}/stems-csv/indeclinable")
  File orthoBuild = new File(buildDir,dataset)
  File fstDir = new File(orthoBuild,"lexica")

  if (! fstDir.exists()) {
    fstDir.mkdir()
  }

  System.err.println "Looking for csv files in " + lexDir
  def fileCount = 0
  lexDir.eachFileMatch(~/.*.csv/) { csvFile ->
    File fstFile = new File(fstDir, "lex-indecl-${csvFile.getName().replaceFirst(/.csv/,'.fst')}")
    fstFile.setText("")
    StringBuilder data = new StringBuilder()
    def lineCount = 0
    csvFile.eachLine { l ->
      ArrayList cols = l.split(/,/)

      // CHECK THAT LINE IS NOT EMPTYR
      if ((lineCount > 0) && (cols.size() > 1)) {
        data.append(indeclFstStringForCols(cols))
      }
      lineCount++
    }
    System.err.println "${fileCount}. File ${csvFile}"
    if (fileCount > 0) {
     fstFile.append(" \\\\|\n")
    }
    fstFile.append(data.toString())
    fileCount++
  }

}



task buildStems(dependsOn: [buildNounStems, buildVerbStems, buildAdjectiveStems, buildIndeclinableStems, buildIrregStems, buildPronounStems]) {
  description = "Builds .fst files from tabular source in data/stems-csv"
  File orthoBuild = new File(buildDir,dataset)
  File fstDir = new File(orthoBuild,"lexica")
  outputs.dir fstDir
}
//
// End methods for writing FST statements for stem lexica from simple tabular source.
/////////////////////////////////////////////////////////////////////////////////////



/////////////////////////////////////////////////////////////////////////////////////
// 
// Tasks to build inflectional rules in FST from source data in .csv files
//

// SOURCE: adjinfl.os_h_on1,os_h_on,os,masc,nom,sg,posit
// TARGET: <os_h_on><u>adjinfl.os_h_on1</u>os<adj><masc><nom><sg><posit>
String adjInflFstForCols(ArrayList cols) {
  if (cols.size() < 7) {
    return ""
  }
  StringBuilder fst = new StringBuilder("")

  String ruleUrn = cols[0].replaceAll(/_/,"\\\\_")
  ruleUrn = ruleUrn.replaceAll("\\.","\\\\.")
  String inflClass = cols[1] //.replaceAll(/_/,"\\_")

  String inflString = cols[2]
  String grammGender = cols[3]
  String grammCase = cols[4]
  String grammNumber = cols[5]
  String degree = cols[6]

  inflString = inflString.replaceAll("_", "<lo>")
  inflString = inflString.replaceAll("\\(", "<ro>")
  inflString = inflString.replaceAll("\\)", "<sm>")
  inflString = inflString.replaceAll("\\|", "\\\\|")


  fst.append(" <${inflClass}><adj>${inflString}<${grammGender}><${grammCase}><${grammNumber}><${degree}><u>${ruleUrn}</u>")
  return fst.toString()
}

String advInflFstForCols(ArrayList cols) {
  if (cols.size() < 4) {
    return ""
  }
  String ruleUrn = cols[0].replaceAll(/_/,"\\\\_")
  ruleUrn = ruleUrn.replaceAll("\\.","\\\\.")
  String inflClass = cols[1] //.replaceAll(/_/,"\\_")
  String inflString = cols[2]
  String degree = cols[3]


  inflString = inflString.replaceAll("_", "<lo>")
  inflString = inflString.replaceAll("\\(", "<ro>")
  inflString = inflString.replaceAll("\\)", "<sm>")
  inflString = inflString.replaceAll("\\|", "\\\\|")
  String fst = "<${inflClass}><adv>${inflString}<${degree}><u>${ruleUrn}</u>"

  return  fst
}
// SOURCE:
// TARGET: <os_h_on><adv>ws<pos><u>advinfl.os_h_on</u>
task buildAdverbInflection(dependsOn:setUpInflDir) {
  description = "Builds rules for adverbs in adverbinfl.fst from tabular source"
}
buildAdverbInflection.doLast {
  File orthoBuild = new File(buildDir, dataset)
  File inflDir = new File(orthoBuild,"inflection")
  File adjFst = new File(inflDir,"adverbinfl.fst")
  adjFst.setText("")
  StringBuilder data = new StringBuilder("\$advinfl\$ = ")

  File lexDir = new File("${loaddir}/${dataset}/rules-csv/adverbs")
  System.err.println "Look for adverbs in " + lexDir
  def fileCount = 0
  lexDir.eachFileMatch(~/.*.csv/) { csvFile ->
    System.err.println "Look at " + csvFile
    if (fileCount > 0) {
      data.append(" |\\\n")
    }
    def lineCount = 0
    csvFile.eachLine { l ->
      ArrayList cols = l.split(/,/)
      if (lineCount == 0) {
	// skip
      } else {
	String fstRow = advInflFstForCols(cols)
	if (fstRow.size() > 1) {
	  if (lineCount == 1) {
	    data.append(fstRow)
	  } else if (lineCount > 1) {
	    data.append(" |\\\n" + fstRow)
	  }
	}
      }
      lineCount++;
    }
    fileCount++
  }
  data.append("\n\n\$advinfl\$\n")
  adjFst.append(data.toString())
}

task buildAdjectiveInflection(dependsOn: setUpInflDir) {
  description = "Builds rules for adjectives in adjectiveinfl.fst from tabular source"

}
buildAdjectiveInflection.doLast {
  File orthoBuild = new File(buildDir, dataset)
  File inflDir = new File(orthoBuild,"inflection")
  File adjFst = new File(inflDir,"adjectiveinfl.fst")
  adjFst.setText("")
  StringBuilder data = new StringBuilder("\$adjinfl\$ = ")

  File lexDir = new File("${loaddir}/${dataset}/rules-csv/adjectives")
  def fileCount = 0
  lexDir.eachFileMatch(~/.*.csv/) { csvFile ->
    if (fileCount > 0) {
      data.append(" |\\\n")
    }
    def lineCount = 0
    csvFile.eachLine { l ->
      ArrayList cols = l.split(/,/)
      if (lineCount == 0) {
	// skip
      } else {
	String fstRow = adjInflFstForCols(cols)
	if (fstRow.size() > 1) {
	  if (lineCount == 1) {
	    data.append(fstRow)
	  } else if (lineCount > 1) {
	    data.append(" |\\\n" + fstRow)
	  }
	}
      }
      lineCount++;
    }
    fileCount++
  }
  data.append("\n\n\$adjinfl\$\n")
  adjFst.append(data.toString())
}


// SOURCE: indeclinfl.2,conjunct
// TARGET: <conjunct><u>indeclinfl.2</u>
String indeclInflFstForCols(ArrayList cols) {
    if (cols.size() < 2) {
    return ""
  }
  StringBuilder fst = new StringBuilder("")

  String ruleUrn = cols[0].replaceAll(/_/,"\\\\_")
  ruleUrn = ruleUrn.replaceAll("\\.","\\\\.")
  String inflClass = cols[1] //.replaceAll(/_/,"\\_")
  fst.append(" <${inflClass}><indecl><u>${ruleUrn}</u>")
  return fst.toString()
  
  return ""
}
task buildIndeclInflection(dependsOn: setUpInflDir) {
  description = "Builds rules for indeclinable forsm in indeclinfl.fst from tabular source"
}
buildIndeclInflection.doLast {
  File orthoBuild = new File(buildDir, dataset)
  File inflDir = new File(orthoBuild,"inflection")
  File indeclFst = new File(inflDir,"indeclinfl.fst")
  indeclFst.setText("")
  StringBuilder data = new StringBuilder("\$indeclinfl\$ = ")

  File lexDir = new File("${loaddir}/${dataset}/rules-csv/indeclinable")
  def fileCount = 0
  lexDir.eachFileMatch(~/.*.csv/) { csvFile ->
    if (fileCount > 0) {
      data.append(" |\\\n")
    }
    def lineCount = 0
    csvFile.eachLine { l ->
      ArrayList cols = l.split(/,/)
      if (lineCount == 0) {
	// skip
      } else {
	String fstRow = indeclInflFstForCols(cols)
	if (fstRow.size() > 1) {
	  if (lineCount == 1) {
	    data.append(fstRow)
	  } else if (lineCount > 1) {
	    data.append(" |\\\n" + fstRow)
	  }
	}
      }
      lineCount++;
    }
    fileCount++
  }
  data.append("\n\n\$indeclinfl\$\n")
  indeclFst.append(data.toString())
}

// Four inflectional patterns for verbs:
//1.
//SOURCE: verbinfl.w_infin1,w_regular,ein,pres,act
// TARGET:  <w_regular>ein<pres><act><infin><u>verbinfl.w_infin1</u>
String infInflFstForCols(ArrayList cols) {
  if (cols.size() < 5) {
    return ""
  }
  StringBuilder fst = new StringBuilder("")

  String ruleUrn = cols[0].replaceAll(/_/,"\\\\_")
  ruleUrn = ruleUrn.replaceAll("\\.","\\\\.")
  String inflClass = cols[1] //.replaceAll(/_/,"\\_")
  String inflString = cols[2]
  String tense = cols[3]
  String voice = cols[4]
  fst.append(" <${inflClass}><infin>${inflString}<${tense}><${voice}><u>${ruleUrn}</u>")
  return fst.toString()  
}
task buildInfInflection(dependsOn: setUpInflDir) {
  description = "Builds rules for infinitive forms of verbs in infinfl.fst from tabular source"
}
buildInfInflection.doLast {
  File orthoBuild = new File(buildDir, dataset)
  File inflDir = new File(orthoBuild,"inflection")
  File infinFst = new File(inflDir,"infininfl.fst")
  infinFst.setText("")
  StringBuilder data = new StringBuilder("\$infininfl\$ = ")

  File lexDir = new File("${loaddir}/${dataset}/rules-csv/infinitives")
  def fileCount = 0
  lexDir.eachFileMatch(~/.*.csv/) { csvFile ->
    if (fileCount > 0) {
      data.append(" |\\\n")
    }
    def lineCount = 0
    csvFile.eachLine { l ->
      ArrayList cols = l.split(/,/)
      if (lineCount == 0) {
	// skip
      } else {
	String fstRow = infInflFstForCols(cols)
	if (fstRow.size() > 1) {
	  if (lineCount == 1) {
	    data.append(fstRow)
	  } else if (lineCount > 1) {
	    data.append(" |\\\n" + fstRow)
	  }
	}
      }
      lineCount++
      }
    fileCount++
  }
  data.append("\n\n\$infininfl\$\n")
  infinFst.append(data.toString())
}


//2.
// SOURCE: verbinfl.w_pres_ptcp1,w_regular,wn,masc,nom,sg,pres,act
// TARGET:  <w_regular>wn<masc><nom><sg><pres><act><ptcpl><u>verbinfl.w_pres_ptcp1</u>
String ptcplInflFstForCols(ArrayList cols) {
    if (cols.size() < 8) {
    return ""
  }
  StringBuilder fst = new StringBuilder("")
  String ruleUrn = cols[0].replaceAll(/_/,"\\\\_")
  ruleUrn = ruleUrn.replaceAll("\\.","\\\\.")
  if (cols.size() < 8) {
    return ""
  }
  String inflClass = cols[1] //.replaceAll(/_/,"\\_")
  String inflString = cols[2]
  
  String gender = cols[3]
  String grammCase = cols[4]
  String grammNumber = cols[5]
  String tense = cols[6]
  String voice = cols[7]

  inflString = inflString.replaceAll("_", "<lo>")
  inflString = inflString.replaceAll("\\(", "<ro>")
  inflString = inflString.replaceAll("\\)", "<sm>")
  inflString = inflString.replaceAll("\\|", "\\\\|")

  fst.append(" <${inflClass}><ptcpl>${inflString}<${gender}><${grammCase}><${grammNumber}><${tense}><${voice}><u>${ruleUrn}</u>")

  return fst.toString()
}

task buildPtcplInflection() {
    description = "Builds rules for participles in ptcplinfl.fst from tabular source"
}
buildPtcplInflection.doLast {
  File orthoBuild = new File(buildDir, dataset)
  File inflDir = new File(orthoBuild,"inflection")
  File ptcplFst = new File(inflDir,"ptcplinfl.fst")
  ptcplFst.setText("")
  StringBuilder data = new StringBuilder("\$ptcplinfl\$ = ")

  File lexDir = new File("${loaddir}/${dataset}/rules-csv/participles")
  def fileCount = 0
  lexDir.eachFileMatch(~/.*.csv/) { csvFile ->
    if (fileCount > 0) {
      data.append(" |\\\n")
    }
    def lineCount = 0
    csvFile.eachLine { l ->
      ArrayList cols = l.split(/,/)
      if (lineCount == 0) {
	// skip
      } else {
	String fstRow = ptcplInflFstForCols(cols)
	if (fstRow.size() > 1) {
	  if (lineCount == 1) {
	    data.append(fstRow)
	  } else if (lineCount > 1) {
	    data.append(" |\\\n" + fstRow)
	  }
	}
      }
      lineCount++
      }
    fileCount++
  }
  data.append("\n\n\$ptcplinfl\$\n")
  ptcplFst.append(data.toString())
}


//3.
// SOURCE: verbinfl.teos_1,w_regular,te/os,masc,nom,sg,vadj1
// TARGET:  <w_regular>te/os<masc><nom><sg><vadj1><u>verbinfl.teos_1</u>
String vadjInflFstForCols(ArrayList cols) {
  if (cols.size() < 7) {
    return ""
  }
  StringBuilder fst = new StringBuilder("")
  
  String ruleUrn = cols[0].replaceAll(/_/,"\\\\_")
  ruleUrn = ruleUrn.replaceAll("\\.","\\\\.")

  String inflClass = cols[1] //.replaceAll(/_/,"\\_")
  String inflString = cols[2]
  
  String gender = cols[3]
  String grammCase = cols[4]
  String grammNumber = cols[5]
  String adjType = cols[6]


  inflString = inflString.replaceAll("_", "<lo>")
  inflString = inflString.replaceAll("\\(", "<ro>")
  inflString = inflString.replaceAll("\\)", "<sm>")
  inflString = inflString.replaceAll("\\|", "\\\\|")

  fst.append(" <${inflClass}><vadj>${inflString}<${gender}><${grammCase}><${grammNumber}><${adjType}><u>${ruleUrn}</u>")
  return fst.toString()
}
task buildVadjInflection(dependsOn: setUpInflDir) {
  description = "Builds rules for verbal adjectives in vadjinfl.fst from tabular source"
}
buildVadjInflection.doLast {

  File orthoBuild = new File(buildDir, dataset)
  File inflDir = new File(orthoBuild,"inflection")
  File vadjFst = new File(inflDir,"vadjinfl.fst")
  vadjFst.setText("")
  StringBuilder data = new StringBuilder("\$vadjinfl\$ = ")

  File lexDir = new File("${loaddir}/${dataset}/rules-csv/verbaladj")
  def fileCount = 0
  lexDir.eachFileMatch(~/.*.csv/) { csvFile ->
    if (fileCount > 0) {
      data.append(" |\\\n")
    }
    def lineCount = 0
    csvFile.eachLine { l ->
      ArrayList cols = l.split(/,/)
      if (lineCount == 0) {
	// skip
      } else {
	String fstRow = vadjInflFstForCols(cols)
	if (fstRow.size() > 1) {
	  if (lineCount == 1) {
	    data.append(fstRow)
	  } else if (lineCount > 1) {
	    data.append(" |\\\n" + fstRow)
	  }
	}
      }
      lineCount++;
    }
    fileCount++
  }
  data.append("\n\n\$vadjinfl\$\n")
  vadjFst.append(data.toString())
}
//4.
// SOURCE:  verbinfl.w_impf_indic1,w_regular,on,1st,sg,impft,indic,act
// TARGET:  <w_regular>es<2nd><sg><impft><indic><act><u>verbinfl.w_impf_indic2</u>
String verbInflFstForCols(ArrayList cols) {
  if (cols.size() < 8) {
    return ""
  }
  StringBuilder fst = new StringBuilder("")
  String ruleUrn = cols[0].replaceAll(/_/,"\\\\_")
  ruleUrn = ruleUrn.replaceAll("\\.","\\\\.")
  if (cols.size() < 8) {
    return ""
  }
  String inflClass = cols[1] //.replaceAll(/_/,"\\_")
  String inflString = cols[2]
  
  String pers = cols[3]
  String num = cols[4]
  String tense = cols[5]
  String mood = cols[6]
  String voice = cols[7]

  inflString = inflString.replaceAll("_", "<lo>")
  inflString = inflString.replaceAll("\\(", "<ro>")
  inflString = inflString.replaceAll("\\)", "<sm>")
  inflString = inflString.replaceAll("\\|", "\\\\|")

  fst.append(" <${inflClass}><verb>${inflString}<${pers}><${num}><${tense}><${mood}><${voice}><u>${ruleUrn}</u>")

  return fst.toString()
}


task buildVerbInflection(dependsOn: setUpInflDir) {
  description = "Builds rules for conjugated verb forms in verbinfl.fst from tabular source"
}
buildVerbInflection.doLast {
  File orthoBuild = new File(buildDir, dataset)
  File inflDir = new File(orthoBuild,"inflection")
  File verbFst = new File(inflDir,"verbinfl.fst")
  verbFst.setText("")
  StringBuilder data = new StringBuilder("\$verbinfl\$ = ")

  File lexDir = new File("${loaddir}/${dataset}/rules-csv/verbs")
  def fileCount = 0
  lexDir.eachFileMatch(~/.*.csv/) { csvFile ->
    if (fileCount > 0) {
      data.append(" |\\\n")
    }
    def lineCount = 0
    csvFile.eachLine { l ->
      ArrayList cols = l.split(/,/)
      if (lineCount == 0) {
	// skip
      } else {
	String fstRow = verbInflFstForCols(cols)
	if (fstRow.size() > 1) {
	  if (lineCount == 1) {
	    data.append(fstRow)
	  } else if (lineCount > 1) {
	    data.append(" |\\\n" + fstRow)
	  }
	}
      }
      lineCount++
      }
    fileCount++
  }
  data.append("\n\n\$verbinfl\$\n")
  verbFst.append(data.toString())
}



String nounInflFstForCols(ArrayList cols) {
  if (cols.size() < 6) {
    return ""
  }
  StringBuilder fst = new StringBuilder("")
  String ruleUrn = cols[0].replaceAll(/_/,"\\\\_")
  ruleUrn = ruleUrn.replaceAll("\\.","\\\\.")
  String inflClass = cols[1].replaceAll(/_/,"\\_")
  String inflString = cols[2]
  String grammGender = cols[3]
  String grammCase = cols[4]
  String grammNumber = cols[5]

  inflString = inflString.replaceAll("_", "<lo>")
  inflString = inflString.replaceAll("\\(", "<ro>")
  inflString = inflString.replaceAll("\\)", "<sm>")
  inflString = inflString.replaceAll("\\|", "\\\\|")


  fst.append(" <${inflClass}><noun>${inflString}<${grammGender}><${grammCase}><${grammNumber}> <u>${ruleUrn}</u>")
  return fst.toString()
}
task buildNounInflection(dependsOn: setUpInflDir) {
  description = "Builds nouninfl.fst from tabular source"
}
buildNounInflection.doLast {
  File orthoBuild = new File(buildDir, dataset)
  File inflDir = new File(orthoBuild,"inflection")
  File nounFst = new File(inflDir,"nouninfl.fst")
  nounFst.setText("")
  StringBuilder data = new StringBuilder("\$nouninfl\$ = ")

  File lexDir = new File("${loaddir}/${dataset}/rules-csv/nouns")
  def fileCount = 0
  lexDir.eachFileMatch(~/.*.csv/) { csvFile ->
    if (fileCount > 0) {
      data.append(" |\\\n")
    }

    def lineCount = 0
    csvFile.eachLine { l ->
      ArrayList cols = l.split(/,/)
      if (lineCount == 0) {
	// skip
      } else {
	String fstRow = nounInflFstForCols(cols)
	if (fstRow.size() > 1) {
	  if (lineCount == 1) {
	    data.append(fstRow)
	  } else if (lineCount > 1) {
	    data.append(" |\\\n" + fstRow)
	  }
	}
      }
      lineCount++
      }
    fileCount++
  }
  data.append("\n\n\$nouninfl\$\n")
  nounFst.append(data.toString())
}


task buildInflection(dependsOn: [buildNounInflection, buildAdjectiveInflection, buildAdverbInflection,buildIndeclInflection, buildInfInflection, buildPtcplInflection, buildVadjInflection,  buildVerbInflection ]) {
  description = "Builds .fst files from tabular source in data/rules-csv"
}


// End methods for writing FST statements from simple tabular source.
/////////////////////////////////////////////////////////////////////////////////






/////////////////////////////////////////////////////////////////////////////////
// Tasks for copying FST source and definition of orthographic system

task cpSrc (type: Copy, dependsOn: [buildStems]) {
    description = "Filters and copies FST src directory to build area."
    from ("src/fst") {
      include ("**/makefile", "**/*.fst")
    }
    into "${buildDir}/${dataset}"
    filter(
      ReplaceTokens, tokens: [
      "workdir" : buildDir.toString() + "/${dataset}/",
      "lexica": lexiconFstStatement(new File("${buildDir}/${dataset}/lexica"))
     ])
    inputs.dir file("${buildDir}/${dataset}/lexica")
}


task cpOrthography(type:Copy, dependsOn: setUpLexDir) {
    description = "Filters and copies directory with defintions of orthographic system to build area."
    from ("${loaddir}/${dataset}/orthography") {
      include ("**/*.fst")
    }
    into "${buildDir}/${dataset}"
}
cpOrthography.doLast {
  System.err.println "Copied orthography data from ${loaddir}/${dataset}/orthography to ${buildDir}/${dataset}"
}


task filterCopy (dependsOn: [cpSrc, cpOrthography]) {
}

task cpAll (dependsOn: [filterCopy, buildInflection] ){
  description = "Copies all source material to build area"
}
cpAll.doLast {
  // check that at least one stem lexicon was copied....
}

// End tasks for copying FST source and definition of orthographic system
/////////////////////////////////////////////////////////////////////////////////






/////////////////////////////////////////////////////////////////////////////////
// Tasks for compiling FSTs

task compileInflection(type:Exec, dependsOn: cpAll) {
  description = "Builds binary Finite State Transducer for core inflection in ${buildDir}/${dataset}/inflection.a"

  outputs.file "${buildDir}/${dataset}/inflection.a".toString()
  inputs.dir "${buildDir}/${dataset}/inflection"

  commandLine =  [MAKE, "-f", "${buildDir}/${dataset}/inflection/makefile".toString()]
}

task fst(type:Exec, dependsOn: [cpAll, compileInflection]) {
  description = "Builds binary Finite State Transducer in ${buildDir}/${dataset}/greek.a"

  outputs.file "${buildDir}/${dataset}/greek.a".toString()
  inputs.dir "${buildDir}/${dataset}"

  commandLine =  [MAKE, "-f", "${buildDir}/${dataset}/makefile".toString()]
}

task fstgen(type:Exec, dependsOn: cpAll) {
  description = "Builds binary Finite State Transducer in ${buildDir}/${dataset}/greek.a and 'switched' FST (for bulk generation of surface symbols) in ${buildDir}/${dataset}/bulkgen.a"

  outputs.file "${buildDir}/${dataset}/bulkgen.a".toString()
  inputs.dir "${buildDir}/${dataset}"

  commandLine =  [FSTCOMPILER, "-s", "${buildDir}/${dataset}/morphology.fst".toString(), "${buildDir}/${dataset}/bulkgen.a".toString()]
}

// End tasks compiling FSTs
/////////////////////////////////////////////////////////////////////////////////



////////////////////////////////////////////////////////////////////////////////////
// Utility transducers, used in testing, helpful in debugging
task rawlex(type:Exec, dependsOn: fst) {
  description = "Builds binary Finite State Transducer in ${buildDir}/${dataset}/rawlex.a"

  outputs.file "${buildDir}/${dataset}/utils/rawlex.a".toString()
  inputs.file "${buildDir}/${dataset}/fst.a"

  commandLine =  [FSTCOMPILER, "${buildDir}/${dataset}/utils/rawlex.fst".toString(), "${buildDir}/${dataset}/utils/rawlex.a".toString()]
}

task rawmorph(type:Exec, dependsOn: fst) {
  description = "Builds binary Finite State Transducer in ${buildDir}/${dataset}/rawmorph.a"

  outputs.file "${buildDir}/${dataset}/utils/rawmorph.a".toString()
  inputs.file "${buildDir}/${dataset}/fst.a"

  commandLine =  [FSTCOMPILER, "${buildDir}/${dataset}/utils/rawmorph.fst".toString(), "${buildDir}/${dataset}/utils/rawmorph.a".toString()]
}

task rawaccepted(type:Exec, dependsOn: rawmorph) {
  description = "Builds binary Finite State Transducer in ${buildDir}/${dataset}/rawaccepted.a"

  outputs.file "${buildDir}/${dataset}/utils/rawaccepted.a".toString()
  inputs.file "${buildDir}/${dataset}/fst.a"

  commandLine =  [FSTCOMPILER, "${buildDir}/${dataset}/utils/rawaccepted.fst".toString(), "${buildDir}/${dataset}/utils/rawaccepted.a".toString()]
}

task utils(dependsOn: [rawlex, rawmorph, rawaccepted]) {
  description = "Compiles utility transducers useful for debugging"
}
utils.doLast {
  System.err.println "Three utility transducers compiled."
}


// End utility transducers used in testing
////////////////////////////////////////////////////////////////////////////////////

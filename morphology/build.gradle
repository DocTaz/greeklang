import org.apache.tools.ant.filters.ReplaceTokens
import org.apache.commons.io.FilenameUtils
import edu.unc.epidoc.transcoder.TransCoder

buildscript {
  repositories {
    mavenCentral()
    maven {
      url "http://beta.hpcc.uh.edu/nexus/content/groups/public"
    }
  }
  dependencies {
    classpath group: 'org.apache.commons', name: 'commons-io', version: '1.3.2'
    classpath group : 'edu.unc.epidoc', name: 'transcoder', version : '1.2-SNAPSHOT'
  }
}

/////////////////////////////////////////////////////////////////////////////////
// Methods generating statements to include in makefile 
//
// Generates appropriate statement to add to makefile dependencies
// for lexica.
String lexiconMakeStatement(File dir) {
  StringBuilder stmt = new StringBuilder()
  def fileList = []
  dir.eachFileMatch(~/.*.fst/) { fstFile ->
    fileList.add ("${buildDir}/${orthography}/${fstFile.getName()}".toString())
  }
  fileList.each { f ->
    stmt.append(f + " ")
  }
  return stmt.toString()
}

// Generates appropriate statements for makefile
// dependencies on compiled inflectional rules.
String rulesMakeStatement(File dir) {
  StringBuilder stmt = new StringBuilder()
  def fileList = []
  dir.eachFileMatch(~/.*.fst/) { fstFile ->
    String compiledFile = fstFile.getName().replaceFirst(/fst$/, "a")
    fileList.add ("${buildDir}/${orthography}/${compiledFile}".toString())
  }
  fileList.each { f ->
    stmt.append(f + " ")
  }
  return stmt.toString()
}

// End methods generating statements to include in makefile.
/////////////////////////////////////////////////////////////////////////////////



/////////////////////////////////////////////////////////////////////////////////
// Methods generating statement to include in FST files.
//
// Generates appropriate SFST-PL statements for including
// compiled files with predefined inflectional rules.
String rulesFstStatement(File dir) {
  StringBuilder stmt = new StringBuilder(" ")
  def fileList = []
  dir.eachFileMatch(~/.*.fst/) { fstFile ->
    String compiledFile = fstFile.getName().replaceFirst(/fst$/, "a")
    fileList.add ('"<' + "${buildDir}/${orthography}/${compiledFile}".toString() + '>"')
  }
  fileList.eachWithIndex { f, i ->
    stmt.append(' | ' + f)
  }

  return stmt.toString()
}

// Generates appropriate SFST-PL statements for including lexica
// in .fst files.
String lexiconFstStatement(File dir) {
  StringBuilder stmt = new StringBuilder()
  def fileList = []

  dir.eachFileMatch(~/.*.fst/) { fstFile ->
    //fileList.add ('"' + "${projectDir}/${fstFile.getName()}".toString() + '"')
    fileList.add ('"' + "${buildDir}/${orthography}/${fstFile.getName()}".toString() + '"')
  }
  fileList.eachWithIndex { f, i ->
    if (i < (fileList.size() - 1)) {
      stmt.append( f + ' | ')
    } else {
      stmt.append( f )
    }

  }
  return stmt.toString()
}

// Generates  SFST-PL statement to add taxonomic tags
// to FST alphabet of symbols.
String tagsFstStatement() {
  return "#extratag# = <epic><hmt><ml>"
}

// End methods generating statement to include in FST files.
/////////////////////////////////////////////////////////////////////////////////





/*
task loadSampleLexica(type: Copy) {
  description = "Copies sample lexicon data in .csv files to active work area."
  from ("sampledata/stems-csv") {
    include ("** / *.csv")
  }
  into "${stemssrcdir}"
}
task loadSampleRules(type: Copy) {
  description = "Copies sample fst rules to active work area."
   from ("sampledata/rules-fst") {
     include "* * / *.fst"
   }
  into "${rulesdir}"
}
task loadSampleData(dependsOn: [loadSampleLexica, loadSampleRules]) {
  description = "Copies sample data sets into active working area"
}
loadSampleData.doLast {
  System.err.println "Sample data sets copied into loading zone."
}
 */


String verbFstStringForCols(ArrayList columns) {

  StringBuilder verbEntry  = new StringBuilder()
  verbEntry.append("<u>${columns[0]}</u>")
  verbEntry.append("<u>${columns[1]}</u>")

  String stem = columns[2].replaceAll("_", "<lo>")
  stem = stem.replaceAll("\\(", "<ro>")
  stem = stem.replaceAll("\\)", "<sm>")
  verbEntry.append(stem)
  verbEntry.append("<verb>")
  verbEntry.append("<${columns[3]}>")
  //verbEntry.append("<${columns[4]}>")
  verbEntry.append("\n")
  return verbEntry.toString()

}
task buildVerbStems() {
  description = "Builds .fst files from tabular source for both simplex and compound verbs"
}

/*
buildVerbStems.doLast {
  File lexDir = new File(projectDir,"${datadir}/${orthography}/stems-csv/verbs-simplex")
  System.err.println "Look for csv files in " + lexDir
  lexDir.eachFileMatch(~/.*.csv/) { csvFile ->
    File fstFile = new File(projectDir, "${datadir}/${orthography}/stems-fst/verbs-${csvFile.getName().replaceFirst(/.csv/,'.fst')}")
    fstFile.setText("")
    StringBuilder data = new StringBuilder()
    def lineCount = 0
    csvFile.eachLine { l ->
      ArrayList cols = l.split(/,/)
      if (lineCount > 0) {
        data.append(verbFstStringForCols(cols))
      }
      lineCount++
    }
    fstFile.append(data.toString())
  }
}
*/
task buildOtherStems() {
  description = "Builds .fst files from tabular source in data/stems-csv/other"
}
buildOtherStems.doLast {
  System.err.println "buildOtherStems not yet implemented."
}
task buildAdjectiveStems() {
  description = "Builds .fst files from tabular source in data/stems-csv/adjectives"
}
buildAdjectiveStems.doLast {
  System.err.println "buildAdjectiveStems not yet implemented."
}

String indeclFstStringForCols(ArrayList columns) {
  StringBuilder indeclEntry  = new StringBuilder()
  indeclEntry.append("<u>${columns[0]}</u>")
  indeclEntry.append("<u>${columns[1]}</u>")
  String stem = columns[2].replaceAll("_", "<lo>")
  stem = stem.replaceAll("\\(", "<ro>")
  stem = stem.replaceAll("\\)", "<sm>")
  indeclEntry.append(stem)
  indeclEntry.append("<indecl>")
  indeclEntry.append("\n")
  return indeclEntry.toString()
}


String nounFstStringForCols(ArrayList columns) {
  StringBuilder nounEntry  = new StringBuilder()
  nounEntry.append("<u>${columns[0]}</u>")
  nounEntry.append("<u>${columns[1]}</u>")
  String stem = columns[2].replaceAll("_", "<lo>")
  stem = stem.replaceAll("\\(", "<ro>")
  stem = stem.replaceAll("\\)", "<sm>")
  nounEntry.append(stem)
  nounEntry.append("<noun>")
  nounEntry.append("<${columns[3]}>")
  nounEntry.append("<${columns[4]}>")
  nounEntry.append("<${columns[5]}>")
  nounEntry.append("\n")
  return nounEntry.toString()
}
task buildNounStems() {
  description = "Builds .fst files from tabular source in ${stemssrcdir}/nouns"
}

buildNounStems.doLast {
  if (! buildDir.exists()) {
    buildDir.mkdir()
  }
  File orthoBuild = new File(buildDir, orthography)
  if (! orthoBuild.exists()) {
    orthoBuild.mkdir()
  }

  File lexDir = new File(projectDir,"${datadir}/${orthography}/stems-csv/nouns")
  System.err.println "Looking for csv files in " + lexDir
  lexDir.eachFileMatch(~/.*.csv/) { csvFile ->
    File fstFile = new File(orthoBuild, "nouns-${csvFile.getName().replaceFirst(/.csv/,'.fst')}")
    fstFile.setText("")
    StringBuilder data = new StringBuilder()
    def lineCount = 0
    csvFile.eachLine { l ->
      ArrayList cols = l.split(/,/)
      if (lineCount > 0) {
        data.append(nounFstStringForCols(cols))
      }
      lineCount++
    }
    fstFile.append(data.toString())
    System.err.println "Wrote noun stems to " + fstFile
  }
  
}

task buildIndeclinableStems() {
  description = "Builds .fst files from tabular source in ${stemssrcdir}/indeclinables"
}
/*
buildIndeclinableStems.doLast {
  File lexDir = new File(projectDir,"${datadir}/${orthography}/stems-csv/indeclinables")
  System.err.println "Look for csv files in " + lexDir
  lexDir.eachFileMatch(~/.*.csv/) { csvFile ->
    File fstFile = new File(projectDir, "${datadir}/${orthography}/stems-fst/indeclinables-${csvFile.getName().replaceFirst(/.csv/,'.fst')}")
    fstFile.setText("")
    StringBuilder data = new StringBuilder()
    def lineCount = 0
    csvFile.eachLine { l ->
      ArrayList cols = l.split(/,/)
      if (lineCount > 0) {
        data.append(indeclFstStringForCols(cols))
      }
      lineCount++
    }
    fstFile.append(data.toString())
  }
}
*/

//task buildStems(dependsOn: [buildNounStems, buildVerbStems, buildAdjectiveStems, buildOtherStems, buildIndeclinableStems]) {
task buildStems(dependsOn: [buildNounStems]) {
  description = "Builds .fst files from tabular source in data/stems-csv"
}

task cpSrc (type: Copy, dependsOn: buildStems) {
    description = "Filters and copies FST src directory to build area."
    from ("src/fst") {
      include ("**/makefile", "**/*.fst")
    }
    into "${buildDir}/${orthography}"
    filter(
      ReplaceTokens, tokens: [
      "workdir" : buildDir.toString() + "/${orthography}/",
      "lexica": lexiconFstStatement(new File("${projectDir}/${datadir}/${orthography}/stems-fst")),
      "makelexica": lexiconMakeStatement(new File("${projectDir}/${datadir}/${orthography}/stems-fst")),
      "fstrules": rulesFstStatement(new File("${projectDir}/${datadir}/${orthography}/rules-fst")),
      "extramakerules": rulesMakeStatement(new File("${projectDir}/${datadir}/${orthography}/rules-fst")),
      "extratags": tagsFstStatement(),
      //"stemurn": getStemUrns(),
      //"lexicon": getLexEntUrns()
     ])
}


task cpCoreInflection(type:Copy) {
    description = "Filters and copies directory with core inflectional rules to build area."
    from ("${projectDir}/${coreinfldir}/${orthography}") {
      include ("**/*.fst", "**/makefile")
    }
    into "${buildDir}/${orthography}"
    filter(ReplaceTokens, tokens: ["workdir" : "${buildDir}/${orthography}/".toString()])
}
cpCoreInflection.doLast {
  System.err.println "Copied ${projectDir}/${coreinfldir} to ${buildDir}/${orthography}"
}
task cpRules (type: Copy, dependsOn: cpCoreInflection) {
    description = "Filters and copies directory with additional inflectional rules to build area."
    from ("${projectDir}/${datadir}/${orthography}/rules-fst") {
      include ("**/*.fst")
    }
    into "${buildDir}/${orthography}"
    filter(ReplaceTokens, tokens: ["workdir" : "${buildDir}/${orthography}/".toString()])
}




task cpAll (dependsOn: [ buildStems, cpRules, cpSrc]){
  description = "Copies all source material to build area"
}
cpAll.doLast {
  // check that at least one stems lexicon was copied.
  Integer lexicaCount = 0
  File stemsDir = new File(projectDir,"${datadir}/${orthography}/stems-fst")
  stemsDir.eachFileMatch(~/.*.fst/) {
    lexicaCount++
  }
  if (lexicaCount == 0) {
    System.err.println ("cpAll: no lexica of stems found in directory ${stemsdir}.")
    throw new Exception("cpAll: no lexica of stems found in directory ${stemsdir}.")
  } else {
    System.err.println "All source files copied to build area."
  }
  System.err.println "Used orthography ${orthography}"
}


//task compileCore(type:Exec, dependsOn: cpCore) {
task compileCore(type:Exec, dependsOn: cpAll) {
  description = "Builds binary Finite State Transducer for core inflection in ${buildDir}/${orthography}/inflection.a"

  outputs.file "${buildDir}/${orthography}/inflection.a".toString()
  inputs.dir "${buildDir}/${orthography}/inflection"

  commandLine =  [MAKE, "-f", "${buildDir}/${orthography}/inflection/makefile".toString()]
}

task fst(type:Exec, dependsOn: [cpAll, compileCore]) {
//task fst(type:Exec, dependsOn: [cpAll]) {
  description = "Builds binary Finite State Transducer in ${buildDir}/${orthography}/greek.a"

  outputs.file "${buildDir}/${orthography}/greek.a".toString()
  inputs.dir "${buildDir}/${orthography}"

  commandLine =  [MAKE, "-f", "${buildDir}/${orthography}/makefile".toString()]
}

task fstgen(type:Exec, dependsOn: cpAll) {
  description = "Builds binary Finite State Transducer in ${buildDir}/${orthography}/greek.a and 'switched' FST (for bulk generation of surface symbols) in ${buildDir}/${orthography}/bulkgen.a"

  outputs.file "${buildDir}/${orthography}/bulkgen.a".toString()
  inputs.dir "${buildDir}/${orthography}"

  commandLine =  [FSTCOMPILER, "-s", "${buildDir}/${orthography}/morphology.fst".toString(), "${buildDir}/${orthography}/bulkgen.a".toString()]
}



////////////////////////////////////////////////////////////////////////////////////
/* ***********  Utility transducers, used in testing, helpful in  debugging  *** */
task rawlex(type:Exec, dependsOn: fst) {
  description = "Builds binary Finite State Transducer in ${buildDir}/${orthography}/rawlex.a"

  outputs.file "${buildDir}/${orthography}/utils/rawlex.a".toString()
  inputs.file "${buildDir}/${orthography}/fst.a"

  commandLine =  [FSTCOMPILER, "${buildDir}/${orthography}/utils/rawlex.fst".toString(), "${buildDir}/${orthography}/utils/rawlex.a".toString()]
}

task rawmorph(type:Exec, dependsOn: fst) {
  description = "Builds binary Finite State Transducer in ${buildDir}/${orthography}/rawmorph.a"

  outputs.file "${buildDir}/${orthography}/utils/rawmorph.a".toString()
  inputs.file "${buildDir}/${orthography}/fst.a"

  commandLine =  [FSTCOMPILER, "${buildDir}/${orthography}/utils/rawmorph.fst".toString(), "${buildDir}/${orthography}/utils/rawmorph.a".toString()]
}

task rawaccepted(type:Exec, dependsOn: rawmorph) {
  description = "Builds binary Finite State Transducer in ${buildDir}/${orthography}/rawaccepted.a"

  outputs.file "${buildDir}/${orthography}/utils/rawaccepted.a".toString()
  inputs.file "${buildDir}/${orthography}/fst.a"

  commandLine =  [FSTCOMPILER, "${buildDir}/${orthography}/utils/rawaccepted.fst".toString(), "${buildDir}/${orthography}/utils/rawaccepted.a".toString()]
}

task utils(dependsOn: [rawlex, rawmorph, rawaccepted]) {
  description = "Compiles utility transducers useful for debugging"
}
utils.doLast {
  System.err.println "Three utility transducers compiled."
}

test.dependsOn utils

// End utility transducers used in testing
////////////////////////////////////////////////////////////////////////////////////


///////////////////////////////////////////////////////////////////////////////
// Debugging and informational tasks:

task exploreSource() {}
exploreSource.doLast {
  System.err.println "Looking for cp.  Here's runtime: "  //sourceSets.main.runtimeClasspath.getFiles().each {
    //System.err.println  it
  //}
  sourceSets {
          main {
              println "java.srcDirs = ${java.srcDirs}"
              println "resources.srcDirs = ${resources.srcDirs}"
              println "java.files = ${java.files.name}"
              println "allJava.files = ${allJava.files.name}"
              println "resources.files = ${resources.files.name}"
              println "allSource.files = ${allSource.files.name}"
              println "output.classesDir = ${output.classesDir}"
              println "output.resourcesDir = ${output.resourcesDir}"
              println "output.files = ${output.files}"
          }
      }
}

task seeSettings () {
}

seeSettings.doLast {
  System.err.println "Settings from fstconf.gradle:"
  def settingsToView =
  [
    "orthography" : orthography,
    "datadir": datadir,
    
    "coreinfldir": coreinfldir,
    "stemsdir": stemsdir,
    "urnregdir" : urnregdir,
    "stemssrcdir" : stemssrcdir,
    "rulesdir" : rulesdir,
    "tagsdir" : tagsdir
  ]

  settingsToView.keySet().each {
    println "${it}: ${settingsToView[it]}"
  }

}

// End debugging and informational tasks.
///////////////////////////////////////////////////////////////////////////////




// IMPLEMENT THIS:
/*
task install() {
  description = "Install binary fst parser and CLI scripts in /usr/local"
}*/
